{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7361a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from frlearn.base import probabilities_from_scores, select_class\n",
    "from frlearn.classifiers import FRNN\n",
    "from frlearn.feature_preprocessors import RangeNormaliser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce488ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indescernibility(matrix,y):\n",
    "    df=pd.DataFrame(matrix)\n",
    "    # this will return the list of columns     \n",
    "    y=list(df.columns)\n",
    "    grouped_df=df.groupby(y)\n",
    "    \n",
    "    ind_R=list(list())\n",
    "    for key, item in grouped_df:\n",
    "#         print(grouped_df.get_group(key), \"\\n\",grouped_df.get_group(key).index ,\"\\n\\n\")\n",
    "        lis=[]\n",
    "        for i in grouped_df.get_group(key).index:\n",
    "            lis.append(i)\n",
    "        ind_R.append(list(lis))\n",
    "    return ind_R\n",
    "\n",
    "def encoding_discourse_type(x):\n",
    "    if x==\"Lead\":\n",
    "        return 0\n",
    "    if x==\"Position\":\n",
    "        return 1\n",
    "    if x==\"Evidence\":\n",
    "        return 2\n",
    "    if x==\"Claim\":\n",
    "        return 3\n",
    "    if x==\"Concluding Statement\":\n",
    "        return 4\n",
    "    if x==\"Counterclaim\":\n",
    "        return 5\n",
    "    if x=='Rebuttal':\n",
    "        return 6\n",
    "    \n",
    "def stemming_stopwords_removing(df):\n",
    "    corpus=[]\n",
    "    for i in range(len(df)):\n",
    "        review=re.sub('[^a-zA-Z]',' ',df[\"discourse_text\"][i])\n",
    "        review=review.lower()\n",
    "        review=review.split()\n",
    "        ps=PorterStemmer()\n",
    "        all_stopwords=stopwords.words(\"english\")\n",
    "        review=[ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "        review=' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "\n",
    "# storing the total occurrence.......\n",
    "def get_total_index_words(corpus):\n",
    "    index_word={}\n",
    "    for i in corpus:\n",
    "        s=i.split()\n",
    "        for j in s:\n",
    "            if j not in index_word:\n",
    "                index_word[j]=1\n",
    "            else:\n",
    "                index_word[j]+=1\n",
    "    return index_word\n",
    "    \n",
    "def get_values (dataset,threshold=1):\n",
    "    \n",
    "    # taking sample of 20 documents for lead category....\n",
    "    df = dataset\n",
    "\n",
    "    total_corpus = stemming_stopwords_removing(df)\n",
    "    # print(total_corpus)\n",
    "\n",
    "    # getting total index words and their count in the taken sample as a dict\n",
    "    total_index_words = get_total_index_words(total_corpus)\n",
    "    # print(len(lead_index_words))\n",
    "\n",
    "    # Creating a list of total keywords before filtering..\n",
    "    total_keywords = list(total_index_words.keys())\n",
    "    # print(lead_keywords)\n",
    "\n",
    "    # Creating a matrix of width equals len(lead_keywords)\n",
    "    matrix=np.zeros((len(df),len(total_keywords)),np.float16)\n",
    "\n",
    "    \n",
    "    # Storing occurrence of each term in each document respectively\n",
    "    for i in range(len(total_corpus)):\n",
    "        s = total_corpus[i].split()\n",
    "        for h in s:\n",
    "            j = total_keywords.index(h)\n",
    "            matrix[i,j] += 1\n",
    "\n",
    "\n",
    "    # Storing their weights....\n",
    "    weighted_matrix = np.copy(matrix)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            weighted_matrix[i,j] = weighted_matrix[i,j] / total_index_words[total_keywords[j]]\n",
    "    #            print(weighted_matrix[i,j])\n",
    "\n",
    "\n",
    "\n",
    "    # FILTERING WEIGHTS with a threshold.......\n",
    "    valid_index = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            if weighted_matrix[i,j] >= threshold:\n",
    "                valid_index.append(j)\n",
    "\n",
    "    # removing duplicates and storing them in a list.......    \n",
    "    valid_index = list(set(valid_index))\n",
    "\n",
    "\n",
    "    # # Storing the final keywords.... \n",
    "    valid_index_words = []\n",
    "    for i in range(len(valid_index)):\n",
    "        valid_index_words.append(total_keywords[valid_index[i]])\n",
    "    # print(valid_lead_index_words)\n",
    "\n",
    "    return total_keywords,total_index_words,matrix, weighted_matrix, valid_index, valid_index_words\n",
    "\n",
    "def get_test_matrix(dataset,total_sample_keywords,threshold=1):\n",
    "      # taking sample of 20 documents for lead category....\n",
    "    df = dataset\n",
    "\n",
    "    total_corpus = stemming_stopwords_removing(df)\n",
    "    # print(total_corpus)\n",
    "\n",
    "    # getting total index words and their count in the taken sample as a dict\n",
    "    total_index_words = get_total_index_words(total_corpus)\n",
    "\n",
    "\n",
    "    # Creating a list of total keywords before filtering..\n",
    "    total_keywords = total_sample_keywords\n",
    "    # print(lead_keywords)\n",
    "\n",
    "    # Creating a matrix of width equals len(lead_keywords)\n",
    "    matrix=np.zeros((len(df),len(total_keywords)),np.float32)\n",
    "    print(len(df),len(total_keywords))\n",
    "\n",
    "    \n",
    "    # Storing occurrence of each term in each document respectively\n",
    "    for i in range(len(total_corpus)):\n",
    "        s = total_corpus[i].split()\n",
    "        for h in s:\n",
    "            try:\n",
    "                j = total_keywords.index(h)\n",
    "                matrix[i,j] += 1\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    # Storing their weights....\n",
    "    weighted_matrix = np.copy(matrix)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            try:\n",
    "                weighted_matrix[i,j] = weighted_matrix[i,j] / total_index_words[total_keywords[j]]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "    # FILTERING WEIGHTS with a threshold.......\n",
    "    valid_index = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            if weighted_matrix[i,j] >= threshold:\n",
    "                valid_index.append(j)\n",
    "\n",
    "    # removing duplicates and storing them in a list.......    \n",
    "    valid_index = list(set(valid_index))\n",
    "\n",
    "\n",
    "    # # Storing the final keywords.... \n",
    "    valid_index_words = []\n",
    "    for i in range(len(valid_index)):\n",
    "        valid_index_words.append(total_keywords[valid_index[i]])\n",
    "    # print(valid_lead_index_words)\n",
    "\n",
    "    return total_keywords,total_index_words,matrix, weighted_matrix, valid_index, valid_index_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44bd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RoughSetsReducer:\n",
    "\n",
    "    def __size(self, x):\n",
    "        return (1, x.shape[0]) if x.ndim == 1 else x.shape\n",
    "\n",
    "    '''\n",
    "    Calculates indiscernibility relation\n",
    "    '''\n",
    "    def indisc(self, a, x):\n",
    "\n",
    "        def codea(a, x, b):\n",
    "            yy = 0\n",
    "            print(a,len(x),b)\n",
    "            for i in range(0, a):\n",
    "                yy += (x[i] * b**(a-(i+1)))\n",
    "\n",
    "            return yy\n",
    "\n",
    "        p, q = self.__size(x)\n",
    "        ap, aq = self.__size(a)\n",
    "        z = [e for e in range(1, q+1)]\n",
    "        tt = np.setdiff1d(z, a)\n",
    "        tt_ind = np.setdiff1d(z, tt)-1\n",
    "        if x.ndim == 1:\n",
    "            x = x[tt_ind]\n",
    "        else:\n",
    "            x = x[:, tt_ind]\n",
    "        y = x\n",
    "        v = [codea(aq, y, 10) for i in range(0, p)] if y.ndim == 1 \\\n",
    "            else [codea(aq, y[i, :], 10) for i in range(0, p)]\n",
    "        y = np.transpose(v)\n",
    "        if y.shape[0] == 1 and len(y.shape) == 1:\n",
    "            I, yy = [1], [y]\n",
    "            y = np.hstack((y, I))\n",
    "            b, k, l = [y], [1], [1]\n",
    "        else:\n",
    "            ax = 1 if y.ndim > 1 else 0\n",
    "            yy = np.sort(y, axis=ax)\n",
    "            I = y.argsort(axis=ax)\n",
    "            y = np.hstack((yy, I))\n",
    "            b, k, l = np.unique(yy, return_index=True, return_inverse=True)\n",
    "        y = np.hstack((l, I))\n",
    "        m = np.max(l)\n",
    "        aa = np.zeros((m+1, p), dtype=int)\n",
    "        for ii in range(0, m+1):\n",
    "            for j in range(0, p):\n",
    "                if l[j] == ii:\n",
    "                    aa[ii, j] = I[j]+1\n",
    "        return aa\n",
    "\n",
    "    '''\n",
    "    Calculates lower approximation set of y\n",
    "    '''\n",
    "    def rslower(self, y, a, T):\n",
    "        z = self.indisc(a, T)\n",
    "        w = []\n",
    "        p, q = self.__size(z)\n",
    "        for u in range(0, p):\n",
    "            zz = np.setdiff1d(z[u, :], 0)\n",
    "            if np.in1d(zz, y).all():\n",
    "                w = np.hstack((w, zz))\n",
    "        return w.astype(dtype=int)\n",
    "\n",
    "    '''\n",
    "    Calculates upper approximation set of y\n",
    "    '''\n",
    "    def rsupper(self, y, a, T):\n",
    "        z = self.indisc(a, T)\n",
    "        w = []\n",
    "        p, q = self.__size(z)\n",
    "        for u in range(0, p):\n",
    "            zz = np.setdiff1d(z[u, :], 0)\n",
    "            zzz = np.intersect1d(zz, y)\n",
    "            if len(zzz) > 0:\n",
    "                w = np.hstack((w, zz))\n",
    "        return w.astype(dtype=int)\n",
    "\n",
    "\n",
    "    def __pospq(self, p, q):\n",
    "        pm, pn = self.__size(p)\n",
    "        qm, qn = self.__size(q)\n",
    "        num = 0\n",
    "        pp, qq = [[]] * pm, [[]] * qm\n",
    "        for i in range(0, pm):\n",
    "            pp[i] = np.unique(p[i, :])\n",
    "        for j in range(0, qm):\n",
    "            qq[j] = np.unique(q[j, :])\n",
    "        b = []\n",
    "        for i in range(0, qm):\n",
    "            for j in range(0, pm):\n",
    "                if np.in1d(pp[j], qq[i]).all():\n",
    "                    num += 1\n",
    "                    b = np.hstack((b, pp[j]))\n",
    "        bb = np.unique(b)\n",
    "        if bb.size == 0:\n",
    "            dd = 1\n",
    "        else:\n",
    "            _, dd = self.__size(bb)\n",
    "        y = float(dd - 1)/pn if 0 in bb else float(dd)/pn\n",
    "        b = np.setdiff1d(bb, 0)\n",
    "        return y, b\n",
    "\n",
    "    '''\n",
    "    Extract core set from C to D\n",
    "    '''\n",
    "    def core(self, C, D):\n",
    "        x = np.hstack((C, D))\n",
    "        c = np.array(range(1, C.shape[1]+1))\n",
    "        d = np.array([C.shape[1]+1])\n",
    "        cp, cq = self.__size(c)\n",
    "        q = self.indisc(d, x)\n",
    "        pp = self.indisc(c, x)\n",
    "        b, w = self.__pospq(pp, q)\n",
    "        a, k, kk, p = ([[]] * cq for i in range(4))\n",
    "        y = []\n",
    "        for u in range(0, cq):\n",
    "            ind = u+1\n",
    "            a[u] = np.setdiff1d(c, ind)\n",
    "            p[u] = self.indisc(a[u], x)\n",
    "            k[u], kk[u] = self.__pospq(p[u], q)\n",
    "            if k[u] != b:\n",
    "                y = np.hstack((y, ind))\n",
    "        return np.array(y)\n",
    "\n",
    "    def __sgf(self, a, r, d, x):\n",
    "        pr = self.indisc(r, x)\n",
    "        q = self.indisc(d, x)\n",
    "        b = np.hstack((r, a))\n",
    "        pb = self.indisc(b, x)\n",
    "        p1, _ = self.__pospq(pb, q)\n",
    "        p2, _ = self.__pospq(pr, q)\n",
    "        return p1 - p2\n",
    "\n",
    "    '''\n",
    "    Return the set of irreducible attributes\n",
    "    '''\n",
    "    def reduce(self, C, D):\n",
    "\n",
    "        def redu2(i, re, c, d, x):\n",
    "            yre = re\n",
    "            re1, re2 = self.__size(re)\n",
    "            q = self.indisc(d, x)\n",
    "            p = self.indisc(c, x)\n",
    "            pos_cd, _ = self.__pospq(p, q)\n",
    "            y, j = None, None\n",
    "            for qi in range(i, re2):\n",
    "                re = np.setdiff1d(re, re[qi])\n",
    "                red = self.indisc(re, x)\n",
    "                pos_red, _ = self.__pospq(red, q)\n",
    "                if np.array_equal(pos_cd, pos_red):\n",
    "                    y = re\n",
    "                    j = i\n",
    "                    break\n",
    "                else:\n",
    "                    y = yre\n",
    "                    j = i + 1\n",
    "                    break\n",
    "            return y, j\n",
    "\n",
    "        x = np.hstack((C, D))\n",
    "        c = np.array(range(1, C.shape[1]+1))\n",
    "        d = np.array([C.shape[1]+1])\n",
    "        y = self.core(C, D)\n",
    "        q = self.indisc(d, x)\n",
    "        p = self.indisc(c, x)\n",
    "        pos_cd, _ = self.__pospq(p, q)\n",
    "        re = y\n",
    "        red = self.indisc(y, x)\n",
    "        pos_red, _ = self.__pospq(red, q)\n",
    "        while pos_cd != pos_red:\n",
    "            cc = np.setdiff1d(c, re)\n",
    "            c1, c2 = self.__size(cc)\n",
    "            yy = [0] * c2\n",
    "            for i in range(0, c2):\n",
    "                yy[i] = self.__sgf(cc[i], re, d, x)\n",
    "            cd = np.setdiff1d(c, y)\n",
    "            d1, d2 = self.__size(cd)\n",
    "            for i in range(d2, c2, -1):\n",
    "                yy[i] = []\n",
    "            ii = np.argsort(yy)\n",
    "            for v1 in range(c2-1, -1, -1):\n",
    "                v2 = ii[v1]\n",
    "                re = np.hstack((re, cc[v2]))\n",
    "                red = self.indisc(re, x)\n",
    "                pos_red, _ = self.__pospq(red, q)\n",
    "        re1, re2 = self.__size(re)\n",
    "        core = y\n",
    "        for qi in range(re2-1, -1, -1):\n",
    "            if re[qi] in core:\n",
    "                y = re\n",
    "                break\n",
    "            re = np.setdiff1d(re, re[qi])\n",
    "            red = self.indisc(re, x)\n",
    "            pos_red, _ = self.__pospq(red, q)\n",
    "            if np.array_equal(pos_cd, pos_red):\n",
    "                y = re\n",
    "        y1, y2 = self.__size(y)\n",
    "        j = 0\n",
    "        for i in range(0, y2):\n",
    "            y, j = redu2(j, y, c, d, x)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b787cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_selection._base import SelectorMixin\n",
    "# from scikit_roughsets.roughsets import RoughSetsReducer\n",
    "\n",
    "\n",
    "class RoughSetsSelector(BaseEstimator, SelectorMixin):\n",
    "\n",
    "    def _get_support_mask(self):\n",
    "        return self.mask_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Missing values are not supported yet!\n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(\"X must not contain any missing values\")\n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(\"y must not contain any missing values\")\n",
    "        # Check that X and Y contains only integer values\n",
    "        if not np.all(np.equal(np.mod(X, 1), 0)):\n",
    "            raise ValueError(\"X must contain only integer values\")\n",
    "        if not np.all(np.equal(np.mod(y, 1), 0)):\n",
    "            raise ValueError(\"y must contain only integer values\")\n",
    "\n",
    "        reducer = RoughSetsReducer()\n",
    "        selected_ = reducer.reduce(X, y)\n",
    "        B_unique_sorted, B_idx = np.unique(np.array(range(X.shape[1])), return_index=True)\n",
    "        B_unique_sorted = B_unique_sorted + 1  # Shift elements by one, as RS index array starts by one\n",
    "        self.mask_ = np.in1d(B_unique_sorted, selected_, assume_unique=True)\n",
    "\n",
    "        if self.mask_.size == 0:\n",
    "            raise ValueError(\"No features were selected by rough sets reducer\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2729776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78edfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e760919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>354946A1CA46</td>\n",
       "      <td>1.623079e+12</td>\n",
       "      <td>2657.0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>Opponents whose work depends on a cell phone l...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 2</td>\n",
       "      <td>450 451 452 453 454 455 456 457 458 459 460 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>1D35A6980E7F</td>\n",
       "      <td>1.622824e+12</td>\n",
       "      <td>388.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>Although it tends to be distracting,</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>73 74 75 76 77 78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>1D35A6980E7F</td>\n",
       "      <td>1.622824e+12</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>Texting while driving is a really problematic ...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 2</td>\n",
       "      <td>328 329 330 331 332 333 334 335 336 337 338 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>40CC76613B2D</td>\n",
       "      <td>1.623002e+12</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>To say that there is a time devices should be ...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>191 192 193 194 195 196 197 198 199 200 201 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>E92185894096</td>\n",
       "      <td>1.622745e+12</td>\n",
       "      <td>2564.0</td>\n",
       "      <td>2695.0</td>\n",
       "      <td>In a nutshell, despite the laws forbidding tex...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>429 430 431 432 433 434 435 436 437 438 439 44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0            id  discourse_id  discourse_start  discourse_end  \\\n",
       "0             0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1             1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2             2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3             3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4             4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "..          ...           ...           ...              ...            ...   \n",
       "135         135  354946A1CA46  1.623079e+12           2657.0         2824.0   \n",
       "136         136  1D35A6980E7F  1.622824e+12            388.0          424.0   \n",
       "137         137  1D35A6980E7F  1.622824e+12           1777.0         1920.0   \n",
       "138         138  40CC76613B2D  1.623002e+12           1120.0         1216.0   \n",
       "139         139  E92185894096  1.622745e+12           2564.0         2695.0   \n",
       "\n",
       "                                        discourse_text discourse_type  \\\n",
       "0    Modern humans today are always on their phone....           Lead   \n",
       "1    They are some really bad consequences when stu...       Position   \n",
       "2    Some certain areas in the United States ban ph...       Evidence   \n",
       "3    When people have phones, they know about certa...       Evidence   \n",
       "4    Driving is one of the way how to get around. P...          Claim   \n",
       "..                                                 ...            ...   \n",
       "135  Opponents whose work depends on a cell phone l...   Counterclaim   \n",
       "136               Although it tends to be distracting,   Counterclaim   \n",
       "137  Texting while driving is a really problematic ...   Counterclaim   \n",
       "138  To say that there is a time devices should be ...   Counterclaim   \n",
       "139  In a nutshell, despite the laws forbidding tex...   Counterclaim   \n",
       "\n",
       "    discourse_type_num                                   predictionstring  \n",
       "0               Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1           Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2           Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3           Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4              Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "..                 ...                                                ...  \n",
       "135     Counterclaim 2  450 451 452 453 454 455 456 457 458 459 460 46...  \n",
       "136     Counterclaim 1                                  73 74 75 76 77 78  \n",
       "137     Counterclaim 2  328 329 330 331 332 333 334 335 336 337 338 33...  \n",
       "138     Counterclaim 1  191 192 193 194 195 196 197 198 199 200 201 20...  \n",
       "139     Counterclaim 1  429 430 431 432 433 434 435 436 437 438 439 44...  \n",
       "\n",
       "[140 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"rough.csv\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c467df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing discourse types in an array fo df1\n",
    "df1_classes=df1[\"discourse_type\"].values\n",
    "\n",
    "# Removing stopwords and performing Porter Stemming....\n",
    "df1_corpus = stemming_stopwords_removing(df1)\n",
    "\n",
    "# getting total index words and their count in the taken sample as a dict\n",
    "df1_index_words = get_total_index_words(df1_corpus)\n",
    "\n",
    "# Creating a list of total keywords before filtering..\n",
    "df1_keywords = list(df1_index_words.keys())\n",
    "\n",
    "total_sample_keywords=df1_keywords.copy()\n",
    "\n",
    "# creating our attributes table for first 20 values of all the 7 different classes\n",
    "attributes=np.zeros((len(df1),len(total_sample_keywords)))\n",
    "\n",
    "# Storing occurrence of each term in each document respectively\n",
    "for i in range(len(df1_corpus)):\n",
    "    s = df1_corpus[i].split()\n",
    "    for h in s:\n",
    "        if h in total_sample_keywords:\n",
    "            j = total_sample_keywords.index(h)\n",
    "            attributes[i,j] += 1\n",
    "            \n",
    "\n",
    "# df1_keywords=list(df1_index_words.keys())\n",
    "# total_sample_keywords\n",
    "# df1_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2cd84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5936705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes=np.array(attributes)\n",
    "len(attributes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1112b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"encoded_dicourse_type\"]=df1[\"discourse_type\"].copy()\n",
    "df1[\"encoded_dicourse_type\"]=df1[\"encoded_dicourse_type\"].apply(lambda x: encoding_discourse_type(x))\n",
    "y1=df1[\"encoded_dicourse_type\"].values\n",
    "y1=np.array([0, 1, 2, 2, 3, 2, 2, 3, 2, 4, 1, 3, 2, 4, 0, 1, 3, 2, 5, 6, 4, 0,\n",
    "       1, 3, 3, 3, 3, 2, 3, 2, 3, 2, 4, 0, 1, 3, 2, 3, 2, 3, 2, 4, 0, 3,\n",
    "       3, 3, 1, 3, 2, 3, 2, 3, 2, 4, 1, 3, 3, 3, 2, 2, 3, 2, 4, 0, 1, 3,\n",
    "       2, 3, 2, 2, 4, 1, 3, 2, 3, 2, 3, 2, 4, 0, 1, 3, 2, 3, 2, 0, 1, 3,\n",
    "       2, 3, 2, 4, 1, 0, 3, 2, 5, 2, 4, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "       5, 5, 5, 5, 5, 5, 5, 5],np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30760d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(attributes, y1, stratify=y1, random_state=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37dc575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = FRNN(preprocessors=(RangeNormaliser(), ))\n",
    "model = clf(X_train, y_train)\n",
    "scores = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3cb75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.7863095238095239\n",
      "accuracy: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Convert scores to probabilities and calculate the AUROC.\n",
    "probabilities = probabilities_from_scores(scores)\n",
    "auroc = roc_auc_score(y_test, probabilities, multi_class='ovo')\n",
    "print('AUROC:', auroc)\n",
    "\n",
    "# Select classes with the highest scores and calculate the accuracy.\n",
    "classes = select_class(scores)\n",
    "\n",
    "accuracy = accuracy_score(y_test, classes)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8623b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf0d1a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 3, 4, 2, 1, 0, 5, 3, 2, 2, 1, 4, 0, 2, 5, 3, 6, 3, 2, 5, 5,\n",
       "       2, 3, 3, 6, 4, 5, 6, 2, 2, 6, 1, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5dda6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70d8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc322d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eba8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c19df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
