{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f075c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d25a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiscernibility(matrix,y):\n",
    "    df=pd.DataFrame(matrix)\n",
    "    # this will return the list of columns     \n",
    "    y=list(df.columns)\n",
    "    grouped_df=df.groupby(y)\n",
    "    \n",
    "    ind_R=list(list())\n",
    "    for key, item in grouped_df:\n",
    "#         print(grouped_df.get_group(key), \"\\n\",grouped_df.get_group(key).index ,\"\\n\\n\")\n",
    "        lis=[]\n",
    "        for i in grouped_df.get_group(key).index:\n",
    "            lis.append(i)\n",
    "        ind_R.append(list(lis))\n",
    "    return ind_R\n",
    "\n",
    "def encoding_discourse_type(x):\n",
    "    if x==\"Lead\":\n",
    "        return 0\n",
    "    if x==\"Position\":\n",
    "        return 1\n",
    "    if x==\"Evidence\":\n",
    "        return 2\n",
    "    if x==\"Claim\":\n",
    "        return 3\n",
    "    if x==\"Concluding Statement\":\n",
    "        return 4\n",
    "    if x==\"Counterclaim\":\n",
    "        return 5\n",
    "    if x=='Rebuttal':\n",
    "        return 6\n",
    "    \n",
    "def stemming_stopwords_removing(df):\n",
    "    corpus=[]\n",
    "    for i in range(len(df)):\n",
    "        review=re.sub('[^a-zA-Z]',' ',df[\"discourse_text\"][i])\n",
    "        review=review.lower()\n",
    "        review=review.split()\n",
    "        ps=PorterStemmer()\n",
    "        all_stopwords=stopwords.words(\"english\")\n",
    "        review=[ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "        review=' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "\n",
    "# storing the total occurrence.......\n",
    "def get_total_index_words(corpus):\n",
    "    index_word={}\n",
    "    for i in corpus:\n",
    "        s=i.split()\n",
    "        for j in s:\n",
    "            if j not in index_word:\n",
    "                index_word[j]=1\n",
    "            else:\n",
    "                index_word[j]+=1\n",
    "    return index_word\n",
    "    \n",
    "def get_values(dataset,threshold=1):\n",
    "    \n",
    "    # taking sample of 20 documents for lead category....\n",
    "    df = dataset\n",
    "\n",
    "    total_corpus = stemming_stopwords_removing(df)\n",
    "    # print(total_corpus)\n",
    "\n",
    "    # getting total index words and their count in the taken sample as a dict\n",
    "    total_index_words = get_total_index_words(total_corpus)\n",
    "    # print(len(lead_index_words))\n",
    "\n",
    "    # Creating a list of total keywords before filtering..\n",
    "    total_keywords = list(total_index_words.keys())\n",
    "\n",
    "    # Creating a matrix of width equals len(lead_keywords)\n",
    "    matrix=np.zeros((len(df),len(total_keywords)))\n",
    "\n",
    "    \n",
    "    # Storing occurrence of each term in each document respectively\n",
    "    for i in range(len(total_corpus)):\n",
    "        s = total_corpus[i].split()\n",
    "        for h in s:\n",
    "            j = total_keywords.index(h)\n",
    "            matrix[i,j] += 1\n",
    "\n",
    "\n",
    "    # Storing their weights....\n",
    "    weighted_matrix = np.copy(matrix)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            weighted_matrix[i,j] = weighted_matrix[i,j] / total_index_words[total_keywords[j]]\n",
    "    #            print(weighted_matrix[i,j])\n",
    "\n",
    "\n",
    "\n",
    "    # FILTERING WEIGHTS with a threshold.......\n",
    "    valid_index = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            if weighted_matrix[i,j] >= threshold:\n",
    "                valid_index.append(j)\n",
    "\n",
    "    # removing duplicates and storing them in a list.......    \n",
    "    valid_index = list(set(valid_index))\n",
    "\n",
    "\n",
    "    # # Storing the final keywords.... \n",
    "    valid_index_words = []\n",
    "    for i in range(len(valid_index)):\n",
    "        valid_index_words.append(total_keywords[valid_index[i]])\n",
    "    # print(valid_lead_index_words)\n",
    "\n",
    "    return total_keywords,total_index_words,matrix, weighted_matrix, valid_index, valid_index_words\n",
    "\n",
    "def get_test_matrix(dataset,total_sample_keywords,threshold=1):\n",
    "      # taking sample of 20 documents for lead category....\n",
    "    df = dataset\n",
    "\n",
    "    total_corpus = stemming_stopwords_removing(df)\n",
    "    # print(total_corpus)\n",
    "\n",
    "    # getting total index words and their count in the taken sample as a dict\n",
    "    total_index_words = get_total_index_words(total_corpus)\n",
    "\n",
    "\n",
    "    # Creating a list of total keywords before filtering..\n",
    "    total_keywords = total_sample_keywords\n",
    "    # print(lead_keywords)\n",
    "\n",
    "    # Creating a matrix of width equals len(lead_keywords)\n",
    "    matrix=np.zeros((len(df),len(total_keywords)))\n",
    "    print(len(df),len(total_keywords))\n",
    "\n",
    "    \n",
    "    # Storing occurrence of each term in each document respectively\n",
    "    for i in range(len(total_corpus)):\n",
    "        s = total_corpus[i].split()\n",
    "        for h in s:\n",
    "            try:\n",
    "                j = total_keywords.index(h)\n",
    "                matrix[i,j] += 1\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    # Storing their weights....\n",
    "    weighted_matrix = np.copy(matrix)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            try:\n",
    "                weighted_matrix[i,j] = weighted_matrix[i,j] / total_index_words[total_keywords[j]]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "    # FILTERING WEIGHTS with a threshold.......\n",
    "    valid_index = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(total_keywords)):\n",
    "            if weighted_matrix[i,j] >= threshold:\n",
    "                valid_index.append(j)\n",
    "\n",
    "    # removing duplicates and storing them in a list.......    \n",
    "    valid_index = list(set(valid_index))\n",
    "    \n",
    "\n",
    "\n",
    "    # # Storing the final keywords.... \n",
    "    valid_index_words = []\n",
    "    for i in range(len(valid_index)):\n",
    "        valid_index_words.append(total_keywords[valid_index[i]])\n",
    "    # print(valid_lead_index_words)\n",
    "\n",
    "    return total_keywords,total_index_words,matrix, weighted_matrix, valid_index, valid_index_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d629bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_element_indiscernibility(matrix,index):\n",
    "    df=pd.DataFrame(matrix)\n",
    "    # this will return the list of columns     \n",
    "    y=list(df.columns)\n",
    "    \n",
    "    grouped_df=df.groupby(y[index])\n",
    "    \n",
    "    ind_R=list(list())\n",
    "    for key, item in grouped_df:\n",
    "    #print(grouped_df.get_group(key), \"\\n\",grouped_df.get_group(key).index ,\"\\n\\n\")\n",
    "        lis=[]\n",
    "        for i in grouped_df.get_group(key).index:\n",
    "            lis.append(i)\n",
    "        ind_R.append(list(lis))\n",
    "    return ind_R\n",
    "\n",
    "def indiscernibility(matrix,y):\n",
    "    if len(y)==0:\n",
    "        return []\n",
    "    df=pd.DataFrame(matrix)\n",
    "    # this will return the list of columns     \n",
    "    grouped_df=df.groupby(y)\n",
    "    ind_R=list(list())\n",
    "    for key, item in grouped_df:\n",
    "    #print(grouped_df.get_group(key), \"\\n\",grouped_df.get_group(key).index ,\"\\n\\n\")\n",
    "        lis=[]\n",
    "        for i in grouped_df.get_group(key).index:\n",
    "            lis.append(i)\n",
    "        ind_R.append(list(lis))\n",
    "    return ind_R\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acf5eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>144288</td>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>if I'm not sure what college I want to attend...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>144289</td>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>seeking multiple opinions before making a har...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>144290</td>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>it is better to seek multiple opinions instead...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>144291</td>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>The impact of asking people to help you make a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>144292</td>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>there are many other reasons one might want to...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index            id  discourse_id  discourse_start  discourse_end  \\\n",
       "0          0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1          1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2          2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3          3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4          4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "...      ...           ...           ...              ...            ...   \n",
       "9995  144288  4C471936CD75  1.618153e+12           2234.0         3203.0   \n",
       "9996  144289  4C471936CD75  1.618153e+12           3221.0         4509.0   \n",
       "9997  144290  4C471936CD75  1.618025e+12           4510.0         4570.0   \n",
       "9998  144291  4C471936CD75  1.618025e+12           4570.0         4922.0   \n",
       "9999  144292  4C471936CD75  1.618025e+12           4935.0         5825.0   \n",
       "\n",
       "                                         discourse_text        discourse_type  \\\n",
       "0     Modern humans today are always on their phone....                  Lead   \n",
       "1     They are some really bad consequences when stu...              Position   \n",
       "2     Some certain areas in the United States ban ph...              Evidence   \n",
       "3     When people have phones, they know about certa...              Evidence   \n",
       "4     Driving is one of the way how to get around. P...                 Claim   \n",
       "...                                                 ...                   ...   \n",
       "9995   if I'm not sure what college I want to attend...              Evidence   \n",
       "9996   seeking multiple opinions before making a har...              Evidence   \n",
       "9997  it is better to seek multiple opinions instead...              Position   \n",
       "9998  The impact of asking people to help you make a...              Evidence   \n",
       "9999  there are many other reasons one might want to...  Concluding Statement   \n",
       "\n",
       "          discourse_type_num  \\\n",
       "0                     Lead 1   \n",
       "1                 Position 1   \n",
       "2                 Evidence 1   \n",
       "3                 Evidence 2   \n",
       "4                    Claim 1   \n",
       "...                      ...   \n",
       "9995              Evidence 2   \n",
       "9996              Evidence 3   \n",
       "9997              Position 1   \n",
       "9998              Evidence 4   \n",
       "9999  Concluding Statement 1   \n",
       "\n",
       "                                       predictionstring  \n",
       "0     1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1          45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2       60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3     76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4     139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "...                                                 ...  \n",
       "9995  386 387 388 389 390 391 392 393 394 395 396 39...  \n",
       "9996  576 577 578 579 580 581 582 583 584 585 586 58...  \n",
       "9997        828 829 830 831 832 833 834 835 836 837 838  \n",
       "9998  839 840 841 842 843 844 845 846 847 848 849 85...  \n",
       "9999  905 906 907 908 909 910 911 912 913 914 915 91...  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "train_head=train.head(5000)\n",
    "train_tail=train.tail(5000)\n",
    "train=pd.concat([train_head,train_tail])\n",
    "train.reset_index(inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48d0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_attr=np.array([[1,0,2,2,1],[0,1,1,1,0],[2,0,0,1,2],[1,1,0,2,1],[1,0,2,0,1],[2,2,0,1,2],[2,1,1,1,2],[0,1,1,0,0]])\n",
    "dec_attr=np.array([0,2,1,2,1,1,2,1])\n",
    "terms=np.array([\"a\",\"b\",\"c\",\"d\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781c5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2 2 1]\n",
      " [0 1 1 1 0]\n",
      " [2 0 0 1 2]\n",
      " [1 1 0 2 1]\n",
      " [1 0 2 0 1]\n",
      " [2 2 0 1 2]\n",
      " [2 1 1 1 2]\n",
      " [0 1 1 0 0]]\n",
      "shape of old training attribute (8, 5)\n",
      "\n",
      "Unique columns: [0, 1, 2, 3]\n",
      "\n",
      "No of unique columns: 4\n",
      "[[1 0 2 1 1 2 2 0]\n",
      " [0 1 0 1 0 2 1 1]\n",
      " [2 1 0 0 2 0 1 1]\n",
      " [2 1 1 2 0 1 1 0]]\n",
      "\n",
      " unique_col_table shape (4, 8)\n",
      "\n",
      "new train attributes after preserving only one repetitve element:\n",
      " [[1 0 2 2]\n",
      " [0 1 1 1]\n",
      " [2 0 0 1]\n",
      " [1 1 0 2]\n",
      " [1 0 2 0]\n",
      " [2 2 0 1]\n",
      " [2 1 1 1]\n",
      " [0 1 1 0]]\n",
      "\n",
      "shape of new train attributes: (8, 4)\n",
      "number of repeated columns are:  0\n"
     ]
    }
   ],
   "source": [
    "# NOW REMOVING IDENTICAL COLUMNS FROM OUR MATRIX INPLACE.......\n",
    "print((c_attr))\n",
    "print(\"shape of old training attribute\",c_attr.shape)\n",
    "grp=np.column_stack(c_attr)\n",
    "temp=pd.DataFrame(grp)\n",
    "# print(temp.shape)\n",
    "\n",
    "temp_grp=indiscernibility(temp,list(temp.columns))\n",
    "# print(temp_grp)\n",
    "\n",
    "unique_columns=[]\n",
    "for i in range(len(temp_grp)):\n",
    "    unique_columns.append(temp_grp[i][0])\n",
    "    \n",
    "unique_columns.sort()\n",
    "print()\n",
    "print(\"Unique columns:\",unique_columns)\n",
    "print(\"\\nNo of unique columns:\",len(unique_columns))\n",
    "\n",
    "unique_col_table=list(list())\n",
    "for i in unique_columns:\n",
    "    unique_col_table.append(list(grp[i]))\n",
    "unique_col_table=np.array(unique_col_table)\n",
    "# print(\"\\nunique_col_table:\")\n",
    "print(unique_col_table)\n",
    "print(\"\\n unique_col_table shape\",unique_col_table.shape)\n",
    "\n",
    "new_train_attributes=np.column_stack(unique_col_table)\n",
    "\n",
    "print(\"\\nnew train attributes after preserving only one repetitve element:\\n\",new_train_attributes)\n",
    "print(\"\\nshape of new train attributes:\",new_train_attributes.shape)\n",
    "c_attr=new_train_attributes.copy()\n",
    "\n",
    "repetitive_columns=list(set(list(range(len(c_attr[0]))))-set(unique_columns))\n",
    "print(\"number of repeated columns are: \", len(repetitive_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e766f747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 2., 2., 0.],\n",
       "       [0., 1., 1., 1., 2.],\n",
       "       [2., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 2., 2.],\n",
       "       [1., 0., 2., 0., 1.],\n",
       "       [2., 2., 0., 1., 1.],\n",
       "       [2., 1., 1., 1., 2.],\n",
       "       [0., 1., 1., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_attr=c_attr.copy()\n",
    "new_arr=np.array([])\n",
    "for i in range(len(combined_attr)):\n",
    "    new_arr=np.append(new_arr,np.append(combined_attr[i],dec_attr[i]))\n",
    "# now reshape it...\n",
    "new_arr=new_arr.reshape(len(dec_attr),len(c_attr[0])+1)\n",
    "combined_attr=new_arr.copy()\n",
    "combined_attr\n",
    "# df1=pd.DataFrame(combined_attr)\n",
    "# print(list(df1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9016fa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : [[1, 7], [0, 3, 4], [2, 5, 6]]\n",
      "b : [[0, 2, 4], [1, 3, 6, 7], [5]]\n",
      "c : [[2, 3, 5], [1, 6, 7], [0, 4]]\n",
      "d : [[4, 7], [1, 2, 5, 6], [0, 3]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(terms)):\n",
    "    print(terms[i],\":\",single_element_indiscernibility(c_attr,i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5268edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indiscernibility: [[7], [1], [4], [0], [3], [2], [6], [5]]\n",
      "[0] : [[1, 7], [0, 3, 4], [2, 5, 6]]\n",
      "[0, 1] : [[1, 7], [0, 4], [3], [2], [6], [5]]\n",
      "[0, 1, 2] : [[1, 7], [0, 4], [3], [2], [6], [5]]\n",
      "[0, 1, 2, 3] : [[7], [1], [4], [0], [3], [2], [6], [5]]\n",
      "[1] : [[0, 2, 4], [1, 3, 6, 7], [5]]\n",
      "[1, 2] : [[2], [0, 4], [3], [1, 6, 7], [5]]\n",
      "[1, 2, 3] : [[2], [4], [0], [3], [7], [1, 6], [5]]\n",
      "[2] : [[2, 3, 5], [1, 6, 7], [0, 4]]\n",
      "[2, 3] : [[2, 5], [3], [7], [1, 6], [4], [0]]\n",
      "[3] : [[4, 7], [1, 2, 5, 6], [0, 3]]\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS ONLY FOR EXPERIMENT PURPOSE...\n",
    "arr=[0,1,2,3]\n",
    "ind=indiscernibility(c_attr,arr)\n",
    "print(\"\\nIndiscernibility:\",ind)\n",
    "res=[arr[i:j] for i in range(len(arr))\n",
    "    for j in range(i+1,len(arr)+1)]\n",
    "\n",
    "for i in res:\n",
    "    print(i,\":\",indiscernibility(c_attr,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d5239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [2, 4, 5, 7], [1, 3, 6]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find R_e as given in the doc......\n",
    "R_e=single_element_indiscernibility(combined_attr,len(combined_attr[0])-1)\n",
    "R_e\n",
    "# Dependency if R_e is always equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94de50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_LA(R_e,ind):\n",
    "    nR_e=list(set())\n",
    "    nind=list(set())\n",
    "    ans=[]\n",
    "    for i in R_e:\n",
    "        nR_e.append(set(i))\n",
    "    for i in ind:\n",
    "        nind.append(set(i))\n",
    "    \n",
    "    for i in range(len(nind)):\n",
    "        for j in range(len(nR_e)):\n",
    "            if nind[i]&nR_e[j]==nind[i]:\n",
    "                for val in nind[i]:\n",
    "                    ans.append(val)\n",
    "    ans=list(set(ans))\n",
    "    return ans\n",
    "\n",
    "def calculate_dependency(R_e,ind,universe=list(range(len(dec_attr)))):\n",
    "     # here universe is set of all objects or terms.\n",
    "    if len(ind)==0:\n",
    "        return 0\n",
    "    ans=calculate_LA(R_e,ind)\n",
    "    return len(ans)/len( universe)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8caefa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0, 1], [0, 1, 2], [0, 1, 2, 3], [1], [1, 2], [1, 2, 3], [2], [2, 3], [3]]\n",
      "[[1 0 2 2]\n",
      " [0 1 1 1]\n",
      " [2 0 0 1]\n",
      " [1 1 0 2]\n",
      " [1 0 2 0]\n",
      " [2 2 0 1]\n",
      " [2 1 1 1]\n",
      " [0 1 1 0]]\n",
      "calculating dependency for all subarrays in array.......\n",
      "\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "1.0\n",
      "0.125\n",
      "0.375\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.25\n",
      "\n",
      "calculating dependency for all single elements.......\n",
      "\n",
      "0.0\n",
      "0.125\n",
      "0.0\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS ONLY FOR EXPERIMENT PURPOSE...CALCULATING DEPENDENCY ----->\n",
    "arr=[0,1,2,3]\n",
    "res=[arr[i:j] for i in range(len(arr))\n",
    "    for j in range(i+1,len(arr)+1)]\n",
    "print(res)\n",
    "print(c_attr)\n",
    "# calculating dependency for all subarrays in array.......\n",
    "print(\"calculating dependency for all subarrays in array.......\")\n",
    "print()\n",
    "for i in res:\n",
    "    ind=indiscernibility(c_attr,i)\n",
    "    print(calculate_dependency(R_e,ind))\n",
    "    \n",
    "# calculating dependency for all single elements.......\n",
    "print()\n",
    "print(\"calculating dependency for all single elements.......\")\n",
    "print()\n",
    "\n",
    "for i in range(len(terms)):\n",
    "    ind=indiscernibility(c_attr,[i])\n",
    "    print(calculate_dependency(R_e,ind))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4e32f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2, 2],\n",
       "       [0, 1, 1, 1],\n",
       "       [2, 0, 0, 1],\n",
       "       [1, 1, 0, 2],\n",
       "       [1, 0, 2, 0],\n",
       "       [2, 2, 0, 1],\n",
       "       [2, 1, 1, 1],\n",
       "       [0, 1, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25dbcfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 3}\n",
      "1.0\n",
      "Old conditional matrix before reducing:\n",
      " [[1 0 2 2]\n",
      " [0 1 1 1]\n",
      " [2 0 0 1]\n",
      " [1 1 0 2]\n",
      " [1 0 2 0]\n",
      " [2 2 0 1]\n",
      " [2 1 1 1]\n",
      " [0 1 1 0]]\n",
      "\n",
      "New conditional matrix after reducing:\n",
      " [[0 2]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 2]\n",
      " [0 0]\n",
      " [2 1]\n",
      " [1 1]\n",
      " [1 0]]\n",
      "\n",
      "Decision matrix is:\n",
      " [0 2 1 2 1 1 2 1]\n",
      "\n",
      "New combined matrix:\n",
      " [[0. 2. 0.]\n",
      " [1. 1. 2.]\n",
      " [0. 1. 1.]\n",
      " [1. 2. 2.]\n",
      " [0. 0. 1.]\n",
      " [2. 1. 1.]\n",
      " [1. 1. 2.]\n",
      " [1. 0. 1.]]\n",
      "\n",
      "New columns as per order:\n",
      " ['b', 'd']\n"
     ]
    }
   ],
   "source": [
    "# QUICK REDUCT ALGO\n",
    "C=[]\n",
    "for i in range(len(c_attr[0])):\n",
    "    C.append(i)\n",
    "C=set(C)\n",
    "R=set()\n",
    "T=set()\n",
    "\n",
    "dep_R=0\n",
    "dep_T=0\n",
    "dep_Re=calculate_dependency(R_e,indiscernibility(c_attr,list(C)))\n",
    "while not dep_R==1:\n",
    "    T=R.copy()\n",
    "    for x in C-R:\n",
    "        dep_R=calculate_dependency(R_e,indiscernibility(c_attr,list(R.union({x}))))\n",
    "        if dep_R>dep_T:\n",
    "            T=R.union({x}).copy()\n",
    "            dep_T=calculate_dependency(R_e,indiscernibility(c_attr,list(T)))\n",
    "    R=T.copy()\n",
    "    dep_R=calculate_dependency(R_e,indiscernibility(c_attr,list(R)))\n",
    "    \n",
    "print(R)\n",
    "print(calculate_dependency(R_e,indiscernibility(c_attr,list(R))))\n",
    "\n",
    "# computing new reduced matrix\n",
    "print(\"Old conditional matrix before reducing:\\n\",c_attr)\n",
    "new_matrix=c_attr[:,list(R)]\n",
    "print(\"\\nNew conditional matrix after reducing:\\n\",new_matrix)\n",
    "# Note: decision attribute will remain the same\n",
    "print(\"\\nDecision matrix is:\\n\",dec_attr)\n",
    "\n",
    "# computing new combined matrix\n",
    "c_attr=new_matrix.copy()\n",
    "combined_attr=c_attr.copy()\n",
    "new_arr=np.array([])\n",
    "for i in range(len(combined_attr)):\n",
    "    new_arr=np.append(new_arr,np.append(combined_attr[i],dec_attr[i]))\n",
    "# now reshape it...\n",
    "new_arr=new_arr.reshape(len(dec_attr),len(c_attr[0])+1)\n",
    "combined_attr=new_arr.copy()\n",
    "print(\"\\nNew combined matrix:\\n\",combined_attr)\n",
    "\n",
    "# Storing final reduced columns list\n",
    "reduced_col=list(R)\n",
    "\n",
    "# storing new_terms\n",
    "new_terms=[]\n",
    "for i in reduced_col:\n",
    "    new_terms.append(terms[i])\n",
    "print(\"\\nNew columns as per order:\\n\",new_terms)\n",
    "new_train_attributes=c_attr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69313e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8deac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aace8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e62bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b66d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b38d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe89323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2488766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b73c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [2], [0], [7], [1, 6], [3], [5]]\n",
      "{4: 0, 2: 1, 0: 2, 7: 3, 1: 4, 6: 4, 3: 5, 5: 6}\n"
     ]
    }
   ],
   "source": [
    "# Calculation fo lower approximation starts here...\n",
    "groups_index={}\n",
    "new_ind=indiscernibility(c_attr,list(range(len(c_attr[0]))))\n",
    "ind=new_ind.copy()\n",
    "print(new_ind)\n",
    "grp=0 # iam following grp index from 0...\n",
    "for i in new_ind:\n",
    "  for j in range(len(i)):\n",
    "    groups_index[i[j]]=grp\n",
    "  grp+=1\n",
    "print(groups_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db2aebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step -1: Find all the rows under one category....\n",
    "def get_class(grp,y):\n",
    "  lead_index=[False]*len(y)\n",
    "  for i in range(len(y)):\n",
    "    if y[i]==grp:\n",
    "      lead_index[i]=True\n",
    "\n",
    "  return lead_index\n",
    "\n",
    "def get_lower_approximation(grp,ind,y):\n",
    "  lead_index=get_class(grp,y)\n",
    "  lower_approximation=[]\n",
    "  for i in ind:\n",
    "    temp=True\n",
    "    for j in range(len(i)):\n",
    "      if not lead_index[i[j]]:\n",
    "        temp=False\n",
    "        break\n",
    "    if temp:\n",
    "      for j in range(len(i)):\n",
    "        lower_approximation.append(i[j])\n",
    "  return lower_approximation\n",
    "\n",
    "def get_upper_approximation(grp,ind,y):\n",
    "  lead_index=get_class(grp,y)\n",
    "  upper_approximation=[]\n",
    "  for i in ind:\n",
    "    temp=False\n",
    "    for j in range(len(i)):\n",
    "      if lead_index[i[j]]:\n",
    "        temp=True\n",
    "        break\n",
    "    if temp:\n",
    "      for j in range(len(i)):\n",
    "        upper_approximation.append(i[j])\n",
    "  return upper_approximation\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "746c4703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower approximation matrix is: [[0], [4, 2, 7, 5], [1, 6, 3]]\n",
      "upper approximation matrix is: [[0], [4, 2, 7, 5], [1, 6, 3]]\n",
      "boundary region matrix is: [[], [], []]\n",
      "outside region matrix is: [[1, 2, 3, 4, 5, 6, 7], [0, 1, 3, 6], [0, 2, 4, 5, 7]]\n"
     ]
    }
   ],
   "source": [
    "# Finding lower apporximation for all the different classes we have and storing it in a matrix....\n",
    "decision_attr=dec_attr.copy()\n",
    "y=decision_attr.copy()\n",
    "\n",
    "def get_lower_approximation_matrix(ind,decision_attr):\n",
    "  lower_approx_matrix=list(list())\n",
    "  y1=np.unique(y)\n",
    "  for i in y1:\n",
    "    lower_approx_matrix.append(list(get_lower_approximation(i,ind,y)))\n",
    "  return lower_approx_matrix\n",
    "\n",
    "lower_approx_matrix=get_lower_approximation_matrix(ind,y)\n",
    "\n",
    "print(\"lower approximation matrix is:\",lower_approx_matrix)\n",
    "\n",
    "    \n",
    "\n",
    "# Finding upper apporximation for all the different classes we have and storing it in a matrix....\n",
    "def get_upper_approximation_matrix(ind,y):\n",
    "  upper_approx_matrix=list(list())\n",
    "  y1=np.unique(y)\n",
    "  for i in y1:\n",
    "    upper_approx_matrix.append(list(get_upper_approximation(i,ind,y)))\n",
    "  return upper_approx_matrix\n",
    "\n",
    "upper_approx_matrix=get_upper_approximation_matrix(ind,y)\n",
    "\n",
    "print(\"upper approximation matrix is:\",upper_approx_matrix)\n",
    "\n",
    "# Defining uuniverse again as U:\n",
    "U=list(range(0,len(y)))\n",
    "universe=set(U)\n",
    "\n",
    "\n",
    "# Finding boundary region for each classes....  \"MAYBE\" region\n",
    "# Now from here on we will use set() datastructure in python and its predefined operations for further calculation....\n",
    "\n",
    "def get_boundary_region_matrix(upper_approx_matrix,lower_approx_matrix):\n",
    "  boundary_reg_matrix=list(list())\n",
    "  for i in range(len(upper_approx_matrix)):\n",
    "    upper_set=set(upper_approx_matrix[i])\n",
    "    lower_set=set(lower_approx_matrix[i])\n",
    "    boundary_reg_matrix.append(list(upper_set-lower_set))\n",
    "  return boundary_reg_matrix\n",
    "\n",
    "boundary_reg_matrix=get_boundary_region_matrix(upper_approx_matrix,lower_approx_matrix)\n",
    "\n",
    "print(\"boundary region matrix is:\",boundary_reg_matrix)\n",
    "# now note boundary region for any class is zero which means that they have equal lower and upper approximation\n",
    "\n",
    "\n",
    "# Finding outside region for each class.... \"NO\" region\n",
    "def get_outside_region_matrix(universe,upper_approx_matrix):\n",
    "  outside_reg_matrix=list(list())\n",
    "  for i in range(len(upper_approx_matrix)):\n",
    "    upper_set=set(upper_approx_matrix[i])\n",
    "    outside_reg_matrix.append(list(universe-upper_set))\n",
    "  return outside_reg_matrix\n",
    "\n",
    "outside_reg_matrix=get_outside_region_matrix(universe,upper_approx_matrix)\n",
    "print(\"outside region matrix is:\",outside_reg_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5cf0109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1}, {0, 1}, {0, 1}]\n",
      "[{1}, {0, 1}, {0, 1}]\n",
      "[set(), set(), set()]\n",
      "[{0}, {0, 1}, {0}]\n"
     ]
    }
   ],
   "source": [
    "def get_set(approx_matrix,attributes):\n",
    "    res=list(set())\n",
    "    temp=[]\n",
    "    for i in approx_matrix:\n",
    "        for j in i:\n",
    "            temp=np.where(attributes[j]!=0)\n",
    "            temp=np.unique(temp)\n",
    "        res.append(set(temp))\n",
    "    return res\n",
    "\n",
    "attr_lower_approx=get_set(lower_approx_matrix,new_train_attributes)\n",
    "attr_upper_approx=get_set(upper_approx_matrix,new_train_attributes)\n",
    "attr_boundary_approx=get_set(boundary_reg_matrix,new_train_attributes)\n",
    "attr_outside_approx=get_set(outside_reg_matrix,new_train_attributes)\n",
    "print(attr_lower_approx)\n",
    "print(attr_upper_approx)\n",
    "print(attr_boundary_approx)\n",
    "print(attr_outside_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc4a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done......\n"
     ]
    }
   ],
   "source": [
    "# REMOVING INCONSISTENCY TUPLES FROM OUR MATRICES using accuracy method...\n",
    "# STEP-1: Find the inconsistent rows.....\n",
    "# NOTE: Deletion of rows is done inplace..so runnnig this cell more than once will give undesirable result\n",
    "\n",
    "# !--NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "def get_inconsistent_rows(ind,y):\n",
    "  inconsistent_rows=list(list())\n",
    "\n",
    "  for i in ind:\n",
    "    if len(i)>1:\n",
    "      temp=y[i[0]]\n",
    "      for j in i:\n",
    "        if y[j]!=temp:\n",
    "          inconsistent_rows.append(list(i))\n",
    "  return inconsistent_rows\n",
    "      \n",
    "\n",
    "inconsistent_rows=get_inconsistent_rows(ind,y)\n",
    "# print(inconsistent_rows)\n",
    "\n",
    "def find_accuracy(inconsistent_rows,lower_approx_matrix):\n",
    "  highest_accuracy=-1\n",
    "  accuracies=list(list())\n",
    "  if len(inconsistent_rows)>0:\n",
    "    # print(inconsistent_rows)\n",
    "    \n",
    "    for i in inconsistent_rows:\n",
    "      lis=[]\n",
    "      for j in i:\n",
    "        cat=y[j]\n",
    "        lower=lower_approx_matrix[cat]\n",
    "        accuracy=len(lower)/len(U)\n",
    "        lis.append(accuracy)\n",
    "      accuracies.append(list(lis))\n",
    "  return accuracies\n",
    "\n",
    "accuracies=find_accuracy(inconsistent_rows,attr_lower_approx)\n",
    "\n",
    "# now note this.. len(inconsistent_rows) and redundant rows will be same...\n",
    "# so each element  in inconsistent_rows has its accuracy stored in accuracies...in the same format that of inconsistent_rows\n",
    "\n",
    "  \n",
    "def find_redundant_rows(accuracies,inconsistent_rows):\n",
    "  redundant_rows=[]\n",
    "  for i in range(len(accuracies)):\n",
    "    max_accuracy=max(accuracies[i])\n",
    "    for j in range(len(accuracies[i])):\n",
    "      if accuracies[i][j]!=max_accuracy:\n",
    "        redundant_rows.append(inconsistent_rows[i][j])\n",
    "  return redundant_rows\n",
    "redundant_rows=find_redundant_rows(accuracies,inconsistent_rows)\n",
    "# print(len(redundant_rows))\n",
    "# print(redundant_rows)\n",
    "\n",
    "\n",
    "# Removing redundant rows if any...\n",
    "\n",
    "if len(redundant_rows)>0:\n",
    "  new_train_attributes=np.delete(new_train_attributes,redundant_rows,axis=0)\n",
    "\n",
    "print(\"Done......\")\n",
    "# DELETEING SAME ROWS FROM decision_attr\n",
    "if len(redundant_rows)>0:\n",
    "  decision_attr=np.delete(decision_attr,redundant_rows,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "682d2d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 2 1 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(decision_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b3d5d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 2]\n",
      " [0 0]\n",
      " [2 1]\n",
      " [1 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(new_train_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b65af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f232b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16c291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3042f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f979c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65837b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917f81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d325fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd062228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde3425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fb2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa2bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4145173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9d81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97e102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ea2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f889e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90239e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
